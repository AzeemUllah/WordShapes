{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this Jupyter notebook implements ideas by prof. Hinrich Schütze in his word shapes lecture:\n",
    "http://www.cis.lmu.de/~hs/teach/15w/intro/pdf/wordshapes.pdf \n",
    "\n",
    "Word shapes can help the computer better understand the nature of an unknown word (out-of-vocabulary). Word shapes can also be used as features for tasks such as Named Entity Recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some preliminaries\n",
    "from collections import defaultdict\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An efficient function that takes a word (as a string) and returns the word shapes (also as a string). The function exploits regular expressions in regex to obtain the word shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_shape(word):\n",
    "    \"Given a word, return its shape\"\n",
    "    \n",
    "    # Replace all lower case letters with ’x’\n",
    "    word_shape = re.sub(r\"[[:lower:]]\", 'x', word)\n",
    "    \n",
    "    # Replace all upper case letters with ’X’\n",
    "    word_shape = re.sub(r\"[[:upper:]]\", 'X', word_shape)\n",
    "    \n",
    "    # Replace all digits letters with ’9’\n",
    "    word_shape = re.sub('\\d', '9', word_shape) \n",
    "    \n",
    "    # “Deduplicate”: any sequence of n > 1 identical characters c\n",
    "    # is replaced by a single copy of c\n",
    "    word_shape = re.sub(r'(.)\\1{1,}', r'\\1', word_shape) \n",
    "    \n",
    "    return word_shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Word compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x-x-x-x'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"state-of-the-art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xx/Xx'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"Myths/Facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x-Xx'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"pre-Islamic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Currency words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'£9.9x'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"£24.4m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$9.9x'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"$15.81m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Words with measurments  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9x/x'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"32km/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9x/x'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"2mm/year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Words with non-ASCII characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"fiancé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xx'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"Über\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Web links and emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x:/x.x/x/'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"https://stackoverflow.com/questions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x.x@x.x'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_shape(\"andrew.johnson@nlp.edu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Words from other languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"x'x\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# French\n",
    "get_word_shape(\"d'accord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xx'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Czech\n",
    "get_word_shape(\"Čecháček\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xx'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Russian\n",
    "get_word_shape(\"Пожалуйста\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, read a large text corpus and populate a word count dictionary. This loop does not read the text file into memory thus a large text file can be processed more efficiently. The text file is assumet to properly tokenized beforehand (e.g., with the standard word tokenizer in NLTK). The monolingual corpus from the workshop in machine translation (WMT) has been used in this analysis. The corpus can be downloaded from here http://www.statmt.org/wmt10/training-monolingual.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = defaultdict(int)\n",
    "\n",
    "with open('/home/badr/word_shapes/news.en.tokenized.all') as f:\n",
    "    for line in f:\n",
    "        for w in line.split():\n",
    "            word_counts[w] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of word types in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261601"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of word tokens in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130643099"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(word_counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the word count dictionary, populate two dictionaries to obtain word shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_counts = defaultdict(int)\n",
    "words_per_shape = defaultdict(set)\n",
    "\n",
    "for word in word_counts:\n",
    "    w_shape = get_word_shape(word) \n",
    "    shape_counts[w_shape] += word_counts[word]\n",
    "    words_per_shape[w_shape].add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of word shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13681"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shape_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Get the most frequent shapes in the corpus and show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape                                                Examples\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "x          antivenoms           stomaches            speke                fillums              decoupaging         \n",
      "Xx         Burullus             Sportica             Krabs                Chalard              Petticoat           \n",
      "X          LHP                  ELMA                 RAYTOWN              MSSC                 BAGATELLE           \n",
      "9          5321                 715931               21284377             20528                430342              \n",
      "'x         'finest              'nearly              'grandstanding       ''nonsense           'sapo               \n",
      "x-x        mad-hatter           shingle-back         check-boxes          busby-haired         semi-homestand      \n",
      "Xx.        Honestly..           Korean..             Col.                 Hartlepool..         Qiyadi..            \n",
      "9.9        183.300              9.885                73.67                2.0158               177.73              \n",
      "x'x        doens't              d'amour              t'wonder             you'ld               n'day               \n",
      "9,9        2,200                15,200               22,447               98,043               4,694               \n",
      "X.X.       M.IA.                E.J.                 P.C.                 M.L.                 L.V.                \n",
      "XxXx       McGwire              InfoNgen             EdOx                 IgNobel              RoomGrooves         \n",
      "9x         60yds                790km                40kms                114c                 276m                \n",
      "9-9        88-48                330-300              64-3                 7-164                3-89                \n",
      "Xx-Xx      Vice-Presidents      Jet-Kingfisher       Fisher-Abt           Trimble-Ritter       Fo-Yo               \n",
      "Xx-x       Bi-ling              Koito-san            Pre-gaming           Web-video            Tyneside-born       \n",
      "9-x        97-store             39-hour              10-tip               3-under              16-ft               \n",
      "9-x-x      71-year-old          120-per-parcel       586-billion-dollar   40-square-mile       5-under-par         \n",
      "x-x-x      six-to-three         percent-plus-one     staff-to-revenue     land-for-land        café-cum-bar        \n",
      "X.         IS..                 GA.                  HSE..                MR..                 RADIO..             \n",
      "x-Xx       ex-Helmet            part-Amazon          predominately-Muslim anti-Rhee            non-Russians        \n",
      "x—x        everyone—even        slogans—along        does—have            output—peaked        playroom—and        \n",
      "x.x        harrods.com          sports.cn            linda.busse          soasta.com           ritzcrackers.com    \n",
      "X9         RD2                  A1075                DC3690               M900                 TJ1                 \n",
      "X.X        HRL.N                FIS.N                ANSS.O               ISH.N                CWTR.O              \n",
      "£9         £342                 £408                 £459                 £201                 £30059              \n",
      "9:9        13:07                16:45                8:13                 05:38                14:31               \n",
      "xXx        eXMeritus            âLeadership          iCel                 pHof                 âBaron              \n",
      "£9,9       £1,918               £26,874              £4,563               £4,441               £4,950              \n",
      "Xx.x       Smartaboutmoney.org  Michaeljackson.com   Armenialiberty.org   Backfence.com        Powerforpresident.com\n",
      "X-x        B-jazz               DEE-fense            FEMA-issued          EC-forced            I-back              \n"
     ]
    }
   ],
   "source": [
    "shape_counts_sorted = sorted(shape_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "s = \"{0:10} {1:20} {2:20} {3:20} {4:20} {5:20}\"\n",
    "\n",
    "print(\"{0:10} {1:>50}\".format('Shape', 'Examples'))\n",
    "print(''.join('-' for _ in range(110)))\n",
    "\n",
    "for (w_shape, count) in shape_counts_sorted[:50]:\n",
    "    words = [w for w in words_per_shape[w_shape]]\n",
    "    \n",
    "    if len(words) > 5:\n",
    "        print(s.format(w_shape, *words[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
